{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2fdbaac",
   "metadata": {},
   "source": [
    "# 인공지능, 머신러닝, 딥러닝\n",
    "\n",
    "## 머신러닝\n",
    "- 문제를 풀 수 있는 데이터가 있고 성과 측정 지표를 가지고 학습을 진행하는 컴퓨터 프로그램\n",
    "- 지도학습 + 비지도학습 + 강화학습\n",
    "- ### 딥러닝 발전요인\n",
    "    - #### Big Data\n",
    "        - 데이터를 처리하는 기술이 발전\n",
    "    \n",
    "    - #### GPU Acceleraltion\n",
    "        - GPU를 필두로한 컴퓨팅 파워의 발전\n",
    "        - 파라미터들을 빨리 찾을 수 있도록 도와줌\n",
    "    \n",
    "    - #### Better Alogrithm\n",
    "        - 새로운 딥러닝 알고리즘의 개발\n",
    "\n",
    "- ### CNN(합성곱 신경망)\n",
    "    - 주어진 이미지에 대해서 작은 점들부터 관촬을 하면서 특성을 찾아나가는 것\n",
    "\n",
    "- ### 지도학습\n",
    "    - 입력데이터를 결합하여 이전에 본 적이 없는 데이터를 적절히 예측하는 방법\n",
    "    \n",
    "---\n",
    "\n",
    "## 딥러닝\n",
    "- 은닉층을 통해 학습하는 것\n",
    "\n",
    "- Cost Function(= Loss Function)\n",
    "    - 뉴럴 네트워크가 실제 갑과 얼마나 비슷한지에 대한 척도\n",
    "    - L = (예측값 - 실제값)^2\n",
    "    \n",
    "- ### 경사하강법\n",
    "    - L 값 미분을 통해 기울기가 감소하는 방향으로 이동하며 최소가 되는 곳을 찾는 것 \n",
    "    - 데이터의 양이 많을 수록 학습속도가 느리다\n",
    "    #### Batch Gradient Descent\n",
    "        - 전체 데이터를 모두 다 사용해 값을 찾는 것\n",
    "    #### Stochastic Gradient Decent\n",
    "        - 랜덤하게 확률적으로 1개의 데이터를 뽑아 계산\n",
    "    #### Mini-batch Gradient Descent\n",
    "        - 전체 데이터 중에 n 개만 뽑아 계산\n",
    "\n",
    "- ### 순전파법(Propagation)\n",
    "    #### 수식을 통해 이해하는 방법\n",
    "    - 각 노드별로 가중치를 곱해한 후 더해줘 은닉층으로 전달\n",
    "    - 은닉층은 받은 값을 시그모이드함수 적용\n",
    "    - 각 은닉층 노드의 값에 가중치를 곱한 후 더해 출력층으로 전달\n",
    "    - 출력층의 예상 갑과 실제 값을 빼고 제곱해 L 값을 구해줌\n",
    "    \n",
    "    #### 계산 그래프를 통한 방법\n",
    "    - 시각적으로 이해하는데 도움이 된다\n",
    "    - 계산 과정을 그래프로 나타낸 것\n",
    "        - 계산 그래프를 구성한다.\n",
    "        - 그래프에서 계산을 왼쪽에서 오른쪽으로 진행한다.\n",
    "            \n",
    "- ### 오차역전파법(Backpropagation)\n",
    "    - Loss로부터 거꾸로 한 단계씩 미분 값을 구하고 이 값들을 chain rule에 의하여 곱해가면서 weight에 대한 gradient를 구하는 방법\n",
    "    #### 수식을 통해 이해하는 방법\n",
    "        - 수식을 사용한 설명은 정확하고 간결하다\n",
    "        - Loss 함수를 거꾸로 편미분 해가며 계산\n",
    "            - chain rule\n",
    "        \n",
    "    #### 계산 그래프를 통한 방법\n",
    "        - 순전파법의 계산 그래프방법을 거꾸로 진행\n",
    "            - 오른쪽 끝 점부터 왼쪽으로 진행\n",
    "        - 덧셈 노드(+) 연전파 하는 법 :\n",
    "            - *1을 해서 그대로 넘겨줌\n",
    "        - 곱셈 노드 (*) 연전파 하는 법 :\n",
    "            - 기울기 그대로 넘겨주고 상대편 값을 곱해 줌\n",
    "        - 계산노드 Python 코드\n",
    "            - https://github.com/WegraLee/deep-learning-from-scratch/blob/master/ch05/buy_apple_orange.py\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba4f56",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
